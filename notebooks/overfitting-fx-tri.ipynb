{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T07:52:48.032954Z",
     "start_time": "2021-01-13T07:52:47.576432Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import utils\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "from copy import deepcopy\n",
    "from tqdm.autonotebook import tqdm\n",
    "import warnings\n",
    "from scipy.stats import ttest_1samp\n",
    "from statsmodels.stats import weightstats as stests\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T07:52:48.064638Z",
     "start_time": "2021-01-13T07:52:48.035316Z"
    }
   },
   "outputs": [],
   "source": [
    "def align_y_pred(y, y_pred, tolerance=4):\n",
    "    \"\"\"\n",
    "    y_pred can be a different timestamp\n",
    "    \"\"\"\n",
    "    left = pd.DataFrame(index=y.index, data={\"y_true\": y})\n",
    "    right = pd.DataFrame(index=y_pred.index, data={\"y_pred\": y_pred})\n",
    "    tmp = pd.merge_asof(left, right, left_index=True, right_index=True,\n",
    "                        tolerance=pd.Timedelta(days=tolerance)).dropna()\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def generate_constraints(daily_ret, config, dn_threshold=0.01, up_threshold=0.99, var_window=260):\n",
    "    def up_cvar(x):\n",
    "        return x[x > 0].quantile(up_threshold)\n",
    "    def dn_cvar(x):\n",
    "        return x[x < 0].quantile(dn_threshold)\n",
    "    \n",
    "    cvar = config[\"CVAR\"]\n",
    "    constraints = pd.DataFrame()\n",
    "    constraints[\"var_dn_1d\"] = daily_ret.expanding(min_periods=var_window).apply(dn_cvar)\n",
    "    constraints[\"var_up_1d\"] = daily_ret.expanding(min_periods=var_window).apply(up_cvar)\n",
    "    constraints[\"var_dn_1w\"] = constraints[\"var_dn_1d\"] * np.sqrt(5)\n",
    "    constraints[\"var_up_1w\"] = constraints[\"var_up_1d\"] * np.sqrt(5)\n",
    "    constraints[\"max_total_size_long\"] = cvar / constraints[\"var_dn_1w\"].abs()\n",
    "    constraints[\"max_total_size_short\"] = cvar / constraints[\"var_up_1w\"].abs()\n",
    "    constraints[\"max_trades\"] = config[\"max_trades\"]\n",
    "    constraints[\"social_size\"] = config[\"social_size\"]\n",
    "    constraints[\"cost\"] = config[\"cost\"]\n",
    "    return constraints\n",
    "\n",
    "\n",
    "def generate_positions(signals, constraints):\n",
    "    positions = [0]    \n",
    "    prev_position = 0\n",
    "    prev_signal = signals.iloc[0]\n",
    "\n",
    "    for i in range(1, len(signals)):\n",
    "        signal = signals.iloc[i]\n",
    "        max_long = constraints['max_total_size_long'].iloc[i]\n",
    "        max_short = constraints['max_total_size_short'].iloc[i]\n",
    "        max_trades = constraints[\"max_trades\"].iloc[i]\n",
    "        social_size = constraints[\"social_size\"].iloc[i]\n",
    "        curr_position = 0\n",
    "        if signal ==0:\n",
    "            if prev_position == 0:\n",
    "                curr_position = 0\n",
    "            elif prev_position > 0:\n",
    "                curr_position = max(0, prev_position - (max_trades * social_size))\n",
    "            elif prev_position < 0:\n",
    "                curr_position = min(0, prev_position + (max_trades * social_size))\n",
    "            else:\n",
    "                raise ValueError(f\"invalid value::prev_position {prev_position} at index: {i}\")\n",
    "        elif signal > 0:\n",
    "            curr_position = min(max_long * signal, prev_position + max_trades * social_size)  \n",
    "        elif signal < 0:\n",
    "            curr_position = max(max_short * signal, prev_position - max_trades * social_size)  \n",
    "        else:\n",
    "            raise ValueError(f\"invalid signla value::signal {signal}  at index: {i}\")\n",
    "        \n",
    "        prev_position = curr_position\n",
    "\n",
    "        positions.append(curr_position)\n",
    "    return pd.Series(index=signals.index, data=positions)\n",
    "\n",
    "\n",
    "def get_sharpe_ratio(daily_pl):\n",
    "    return daily_pl.mean() / (1e-10 + daily_pl.std()) * np.sqrt(252)\n",
    "\n",
    "\n",
    "def generate_daily_states(y, y_pred, constraints, delay=0):\n",
    "    tmp = align_y_pred(y, y_pred)\n",
    "    y_pred = tmp[\"y_pred\"]\n",
    "    y_true = tmp[\"y_true\"]\n",
    "    positions = generate_positions(y_pred, constraints)\n",
    "    daily_pl = positions * (y_true - constraints[\"cost\"]).shift(-delay).fillna(0)\n",
    "    return daily_pl, positions\n",
    "\n",
    "\n",
    "def sharpe_score(y, y_pred, constraints, delay=0):\n",
    "    daily_pl, daily_pos = generate_daily_states(y, y_pred, constraints, delay)\n",
    "    return get_sharpe_ratio(daily_pl)\n",
    "\n",
    "\n",
    "def sharpe_score_no_cost(y, y_pred, delay=0):\n",
    "    tmp = align_y_pred(y, y_pred)\n",
    "    y_pred = tmp[\"y_pred\"]\n",
    "    y_true = tmp[\"y_true\"]\n",
    "    daily_pl = y_pred * y_true.shift(-delay).fillna(0)\n",
    "    return get_sharpe_ratio(daily_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T07:52:48.090524Z",
     "start_time": "2021-01-13T07:52:48.066594Z"
    }
   },
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, space, score_func, random_state=0, n_rounds=10, n_calls=10):\n",
    "        self.space = space\n",
    "        self.score_func = score_func\n",
    "        self.random_state = random_state\n",
    "        self.n_rounds = n_rounds\n",
    "        self.n_calls = n_calls\n",
    "    \n",
    "    def optimize(self, estimator, X, y):\n",
    "        best_params = None\n",
    "        best_val = -100\n",
    "        for values in product(*self.space.values()):\n",
    "            params = {key: val for key, val in zip(self.space.keys(), values)}\n",
    "            estimator.set_params(**params)\n",
    "            score = self.score_func(y, estimator.predict(X))\n",
    "            if score > best_val:\n",
    "                best_val = score\n",
    "                best_params = params\n",
    "        estimator.set_params(**best_params)\n",
    "        return estimator, best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T07:52:48.349122Z",
     "start_time": "2021-01-13T07:52:48.258542Z"
    }
   },
   "outputs": [],
   "source": [
    "class WalkForwardSplit:\n",
    "    \"\"\"\n",
    "    To create split to online update models.\n",
    "\n",
    "    expanding window:\n",
    "    |-------train-----------|---gap---|----test-----|\n",
    "    \n",
    "    rolling window:\n",
    "                |---train---|---gap---|----test-----|\n",
    "    \n",
    "    In situations where the \"y\" is observed with a delay of `gap`, one can\n",
    "    only train model and deploy it on test set with a gap.\n",
    "    \n",
    "    Parameter\n",
    "    ----------------------\n",
    "\n",
    "    train_size: int/float\n",
    "    gap: int, The delay in deploying the trained model.\n",
    "    test_size: int/float\n",
    "    expanding: bool, (default = False)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_size, test_size, gap, expanding=False):\n",
    "        self.train_size = train_size\n",
    "        self.test_size = test_size\n",
    "        self.gap = gap\n",
    "        self.expanding = expanding\n",
    "    \n",
    "    def get_size(self, sz, y):\n",
    "        if isinstance(sz, int):\n",
    "            return sz\n",
    "        elif isinstance(sz, float):\n",
    "            assert sz <= 1 and sz >= 0\n",
    "            return int(sz * len(y))\n",
    "        else:\n",
    "            raise ValueError(f\"sz must be an integer or float in [0, 1], it is {sz} now.\")\n",
    "\n",
    "    def split(self, y, verbose=True):\n",
    "        train_size = self.get_size(self.train_size, y)\n",
    "        test_size = self.get_size(self.test_size, y)\n",
    "        gap = self.gap\n",
    "        splits = self._split(y, train_size, test_size, gap)\n",
    "\n",
    "        if verbose:\n",
    "            return tqdm(splits, total=np.ceil((len(y) - train_size - gap) / test_size))\n",
    "        else:\n",
    "            return splits\n",
    "    \n",
    "    def _split(self, y, train_size, test_size, gap):\n",
    "        min_test_start = train_size + gap\n",
    "        \n",
    "        for test_start in range(min_test_start, len(y), test_size):\n",
    "            if self.expanding:\n",
    "                train_start = 0\n",
    "            else:\n",
    "                train_start = test_start - min_test_start\n",
    "            train_end = test_start - gap\n",
    "            test_end = min(test_start + self.test_size, len(y))\n",
    "            yield np.arange(train_start, train_end), np.arange(test_start, test_end)\n",
    "\n",
    "            \n",
    "def walkforward_training(X, y, model, splitter):\n",
    "    y_pred = pd.Series(index=y.index, data=np.nan)\n",
    "    models = []\n",
    "    for train_idx, test_idx in splitter.split(y):\n",
    "        mdl = deepcopy(model)\n",
    "        mdl.fit(X, y[train_idx])\n",
    "        y_pred_tmp = mdl.predict(X)\n",
    "        \n",
    "        # after fitting on train, we write down the train/test prediction on the batch\n",
    "        tmp = align_y_pred(y[test_idx], y_pred_tmp)\n",
    "        y_pred_test = tmp[\"y_pred\"]\n",
    "\n",
    "        tmp = align_y_pred(y[train_idx], y_pred_tmp)\n",
    "        y_pred_train = tmp[\"y_pred\"]\n",
    "        \n",
    "        y_pred[test_idx] = y_pred_test\n",
    "        models.append([mdl, train_idx, test_idx, y_pred_train, y_pred_test])\n",
    "\n",
    "    return models, y_pred\n",
    "\n",
    "\n",
    "print(\"checking the splitter is right\")\n",
    "\n",
    "print(\"rolling window: \")\n",
    "splitter = WalkForwardSplit(train_size=0.5, test_size=10, gap=1)\n",
    "y = np.arange(100)\n",
    "for train, test in splitter.split(y):\n",
    "    print(f\"train set: {train[0]} -- {train[-1]}, test set: {test[0]} -- {test[-1]}\")\n",
    "    \n",
    "\n",
    "print(\"expanding window: \")\n",
    "splitter = WalkForwardSplit(train_size=0.5, test_size=10, gap=1, expanding=True)\n",
    "y = np.arange(100)\n",
    "for train, test in splitter.split(y):\n",
    "    print(f\"train set: {train[0]} -- {train[-1]}, test set: {test[0]} -- {test[-1]}\")\n",
    "    \n",
    "\n",
    "print(\"rounding off: \")\n",
    "splitter = WalkForwardSplit(train_size=0.3, test_size=15, gap=3, expanding=True)\n",
    "y = np.arange(100)\n",
    "for train, test in splitter.split(y):\n",
    "    print(f\"train set: {train[0]} -- {train[-1]}, test set: {test[0]} -- {test[-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T07:52:48.499475Z",
     "start_time": "2021-01-13T07:52:48.473314Z"
    }
   },
   "outputs": [],
   "source": [
    "class HybridEstimator:\n",
    "    def __init__(self, base_estimator, optimizer):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        best_model, _ = self.optimizer.optimize(self.base_estimator, X, y)\n",
    "        self.base_estimator = best_model\n",
    "        return self.base_estimator\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.base_estimator.predict(X)\n",
    "\n",
    "\n",
    "class HybridBaseEstimator:\n",
    "    def __init__(self, **params):\n",
    "        self.params = dict()\n",
    "        self.set_params(**params)\n",
    "        \n",
    "    def set_params(self, **params):\n",
    "        self.params.update(params)\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.params\n",
    "    \n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError(\"no\")\n",
    "\n",
    "    def zscore(self, x, **kwargs):\n",
    "        grp = x.ewm(**kwargs)\n",
    "        return (x - grp.mean()) / (1e-10 + grp.std())\n",
    "\n",
    "    def get_weighted_sum(self, x, weights):\n",
    "        # get the weighted sum of an arithmatic weight series\n",
    "        # compute x.rolling(len(weights)).apply(lambda x: sum(y * w for y, w in zip([x, weights])))\n",
    "        n = len(weights)\n",
    "        cx = x.cumsum()\n",
    "        gap = weights[-1] - weights[-2]\n",
    "        return weights[-1] * cx - gap * cx.rolling(n-1).sum().shift() - weights[0] * cx.shift(n)\n",
    "\n",
    "\n",
    "class DiffReturn(HybridBaseEstimator):\n",
    "    def predict(self, X):\n",
    "        return self.get_params()[\"direction\"] * np.sign(X.diff(self.get_params()[\"window\"])).fillna(0)\n",
    "        \n",
    "\n",
    "class WeightedReturn(HybridBaseEstimator):\n",
    "    def predict(self, X):\n",
    "        n = self.get_params()[\"window\"]\n",
    "        signal = n * X - X.rolling(n).sum().shift()\n",
    "        return self.get_params()[\"direction\"] * np.sign(signal).fillna(0)\n",
    "\n",
    "\n",
    "class ZScoreTrend(HybridBaseEstimator):\n",
    "    def predict(self, X):\n",
    "        zscore = self.zscore(X, halflife=self.get_params()[\"window\"])\n",
    "        return self.get_params()[\"direction\"] * np.sign(zscore).fillna(0)\n",
    "\n",
    "\n",
    "class OLSTrendSignal(HybridBaseEstimator):\n",
    "    def predict(self, X):\n",
    "        n = self.params[\"window\"]\n",
    "        weights = np.arange(n)\n",
    "        cov_xy = self.get_weighted_sum(X, weights)\n",
    "        cov_xmu = X.rolling(n).sum() * weights.sum() / n\n",
    "        beta = (cov_xy - cov_xmu) / np.var(weights) / n\n",
    "        return self.get_params()[\"direction\"] * np.sign(beta).fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trend/reversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T09:10:42.839457Z",
     "start_time": "2021-01-13T08:57:55.623654Z"
    }
   },
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"ADXY\": {\n",
    "        \"CVAR\": 1e7,\n",
    "        \"social_size\": 1e6,\n",
    "        \"max_trades\": 5000,\n",
    "        \"cost\": 0.00666 * 1e-2\n",
    "    },\n",
    "    \"TRY\": {\n",
    "        \"CVAR\": 1e7,\n",
    "        \"social_size\": 1e6,\n",
    "        \"max_trades\": 600,\n",
    "        \"cost\": 0.05\n",
    "    }\n",
    "}\n",
    "\n",
    "estimators = {\n",
    "    \"zscore\": ZScoreTrend(),\n",
    "    \"past-diff\": DiffReturn(),\n",
    "    \"ols-beta\": OLSTrendSignal(),\n",
    "    \"weighted-gap\": WeightedReturn()\n",
    "}\n",
    "\n",
    "\n",
    "spaces = {\n",
    "    \"short\": range(3, 10),\n",
    "    \"medium\": range(15, 30),\n",
    "    \"long\": range(50, 150, 5)\n",
    "}\n",
    "\n",
    "\n",
    "index = \"TRY\"\n",
    "\n",
    "config = configs[index]\n",
    "tri = utils.get_total_return_index(index)\n",
    "constraints = generate_constraints(tri[\"tri\"].diff(), config).ffill().bfill()\n",
    "X = utils.get_total_return_index(index)[\"tri\"]\n",
    "y = X.diff().shift(-1)\n",
    "\n",
    "\n",
    "stats = []\n",
    "score_func = partial(sharpe_score, delay=0, constraints=constraints)\n",
    "\n",
    "scores = {\n",
    "    \"sharpe-cost\": score_func,\n",
    "    \"sharpe-cost-delay-1\": partial(sharpe_score, delay=1, constraints=constraints),\n",
    "    \"sharpe-no-cost\": partial(sharpe_score_no_cost, delay=0),\n",
    "    \"sharpe-no-cost-delay-1\": partial(sharpe_score_no_cost, delay=1),\n",
    "}\n",
    "\n",
    "\n",
    "# define horizon\n",
    "studies = list(product(spaces.items(), estimators.items()))\n",
    "for idx, ((term, search), (estimator_name, base_estimator)) in tqdm(enumerate(studies)):\n",
    "    space = {\"window\": search, \"direction\": [-1, 1]}\n",
    "    optimizer = Optimizer(space, score_func)\n",
    "    hybrid = HybridEstimator(base_estimator, optimizer)\n",
    "    splitter = WalkForwardSplit(train_size=0.5, test_size=252, gap=0, expanding=True)\n",
    "    models, y_pred = walkforward_training(X, y, hybrid, splitter)\n",
    "\n",
    "    f = y_pred.notnull() & y.notnull()\n",
    "    cnt = f.sum()\n",
    "    directions = np.array([x[0].base_estimator.get_params()[\"direction\"] for x in models])\n",
    "    best_window = np.array([x[0].base_estimator.get_params()[\"window\"] for x in models])\n",
    "    zstat = stests.ztest(y[f] * y_pred[f], x2=None, alternative=\"larger\")\n",
    "\n",
    "    xx = defaultdict(list)\n",
    "    for model, train_idx, test_idx, y_pred_train, y_pred_test in models:\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        for func_name, func in scores.items():\n",
    "            xx[func_name].append([func(y_train, y_pred_train), func(y_test, y_pred_test)])\n",
    "\n",
    "    d = dict(index=index, estimator_name=estimator_name, term=term, cnt=cnt,\n",
    "             zstat=zstat[0], pval=zstat[1], directions=directions,\n",
    "             window=best_window)\n",
    "    yy = {func_name: np.array(vals) for func_name, vals in xx.items()}\n",
    "    d.update(yy)\n",
    "    d[\"y_true\"] = y\n",
    "    d[\"y_pred\"] = y_pred\n",
    "    \n",
    "    for score_name, func in scores.items():\n",
    "        d[score_name + \"_all\"] = func(y, y_pred)\n",
    "    stats.append(d)\n",
    "\n",
    "    daily_pl, daily_pos = generate_daily_states(y, y_pred, constraints, delay=0)\n",
    "    d[\"daily_pl\"] = daily_pl\n",
    "    d[\"position\"] = daily_pos \n",
    "stats = pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T09:15:25.130188Z",
     "start_time": "2021-01-13T09:15:25.101076Z"
    }
   },
   "outputs": [],
   "source": [
    "from data_analysis_toolbox import gscatter, statx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T09:21:55.518330Z",
     "start_time": "2021-01-13T09:21:55.272780Z"
    }
   },
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T09:18:30.168120Z",
     "start_time": "2021-01-13T09:18:30.134973Z"
    }
   },
   "outputs": [],
   "source": [
    "stats[\"pval\"].le(0.05).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T09:22:14.553864Z",
     "start_time": "2021-01-13T09:22:14.521383Z"
    }
   },
   "outputs": [],
   "source": [
    "statx(stats.iloc[5][\"sharpe-cost\"])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T09:13:34.390255Z",
     "start_time": "2021-01-13T09:13:34.213297Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(stats.iloc[5][\"daily_pl\"].cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T06:47:34.709774Z",
     "start_time": "2021-01-13T06:47:34.563231Z"
    }
   },
   "outputs": [],
   "source": [
    "score_name = \"sharpe-no-cost\"\n",
    "xx = stats[score_name].values\n",
    "xx = np.vstack(xx)\n",
    "plt.scatter(xx[:, 0], xx[:, 1])\n",
    "plt.xlabel(\"train score\")\n",
    "plt.ylabel(\"val score\")\n",
    "plt.title(score_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T06:14:38.967990Z",
     "start_time": "2021-01-13T06:14:38.662030Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_random = pd.Series(index=y.index, data=np.sign(np.random.randn(len(y))))\n",
    "print(\"with cost:\", sharpe_score(y, y_pred_random, constraints=constraints))\n",
    "print(\"with no cost:\", sharpe_score_no_cost(y, y_pred_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T07:17:30.553898Z",
     "start_time": "2021-01-11T07:17:21.591Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats = []\n",
    "tris = [\n",
    "    \"SGDINR\",\n",
    "    \"TRY\",\n",
    "    \"CNHTWD\",\n",
    "    \"TWD1m\",\n",
    "    \"CNH1m\",\n",
    "    \"ADXY\",\n",
    "    \"CNYCNH\",\n",
    "    \"CNH2y\",\n",
    "    \"CNH3m\",\n",
    "    \"HUFCZK\",\n",
    "    \"RUBvsEUR\",\n",
    "    \"CNH3m12m\",\n",
    "    \"IDR1m3m\",\n",
    "    \"CNH12m\",\n",
    "    \"CNH6m\",\n",
    "    \"CNH\",\n",
    "    \"TWD1m3m\",\n",
    "    \"AUDJPY\",\n",
    "    \"TWD3m12m\"\n",
    "]\n",
    "\n",
    "score_func = partial(sharpe_score, delay=0)\n",
    "score_func_1 = partial(sharpe_score, delay=1)\n",
    "\n",
    "estimators = {\n",
    "    \"zscore\": ZScoreTrend(),\n",
    "    \"past-diff\": DiffReturn(),\n",
    "    \"ols-beta\": OLSTrendSignal(),\n",
    "    \"weighted-gap\": WeightedReturn()\n",
    "}\n",
    "\n",
    "\n",
    "spaces = {\n",
    "    \"short\": range(3, 10),\n",
    "    \"medium\": range(15, 30),\n",
    "    \"long\": range(50, 150)\n",
    "}\n",
    "\n",
    "\n",
    "for index in tqdm(tris):\n",
    "    X = utils.get_total_return_index(index=index)[\"tri\"]\n",
    "    \n",
    "    y = X.diff().shift(-1)\n",
    "    # define horizon\n",
    "    for term, search in spaces.items():\n",
    "        # define the concrete base estimator\n",
    "        for name, base_estimator in estimators.items():\n",
    "            space = {\"window\": search, \"direction\": [-1, 1]}\n",
    "            optimizer = Optimizer(space, score_func)\n",
    "            hybrid = HybridEstimator(base_estimator, optimizer)\n",
    "            splitter = WalkForwardSplit(train_size=0.5, test_size=252, gap=0, expanding=True)\n",
    "            models, y_pred = walkforward_training(X, y, hybrid, splitter)\n",
    "            f = y_pred.notnull() & y.notnull()\n",
    "            cnt = f.sum()\n",
    "            direction = np.mean([x[0].base_estimator.get_params()[\"direction\"] for x in models])\n",
    "            best_window = np.mean([x[0].base_estimator.get_params()[\"window\"] for x in models])\n",
    "            zstat =stests.ztest(y[f] * y_pred[f], x2=None, alternative=\"larger\")\n",
    "            score = score_func(y, y_pred)\n",
    "            score_delay = score_func_1(y, y_pred)\n",
    "            d = dict(index=index, name=name, term=term, sharpe=score, sharpe_delay1=score_delay,\n",
    "                     cnt=cnt, zstat=zstat[0], pval=zstat[1], direction=direction, window=best_window)\n",
    "            stats.append(d)\n",
    "            \n",
    "stats = pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T02:58:41.147906Z",
     "start_time": "2021-01-05T02:58:41.080222Z"
    }
   },
   "outputs": [],
   "source": [
    "#### short term signal is more sensitive to delay\n",
    "stats = pd.read_csv(\"tri_momentum_reversion_stats.csv\")\n",
    "print(\"percentage of trail that passed 5% test:\", 100 * stats[\"pval\"].le(0.05).mean(0))\n",
    "stats.set_index(\"index\").to_csv(\"tri_momentum_reversion_stats.csv\")\n",
    "stats[stats[\"pval\"].le(0.05)].groupby(\"term\")[[\"sharpe\", \"sharpe_delay1\"]].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### guolong's sentiment trading strategy\n",
    "go short if both zscore and sentiment are negative, otherwise go long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:31:50.313557Z",
     "start_time": "2021-01-05T09:31:49.565836Z"
    }
   },
   "outputs": [],
   "source": [
    "X = utils.get_ssl_sentiment()\n",
    "\n",
    "underlyings = [\n",
    "    \"SPX\", \"NDX\", \"NKY\", \"HSCEI\", \"HSI\", \"KOSPI2\", \"SX5E\", \"DAX\",\n",
    "    \"HYG\", \"TLT\", \"LQD\",\n",
    "    \"GLD\", \"USO\",\n",
    "    \"USDNOK\", \"USDRUB\", \"USDMXN\", \"AUDJPY\"\n",
    "]\n",
    "\n",
    "spaces = {\n",
    "    \"short\": range(3, 10),\n",
    "    \"medium\": range(15, 30, 2),\n",
    "    \"long\": range(50, 150, 5)\n",
    "}\n",
    "\n",
    "class SentimentSignal(HybridBaseEstimator):\n",
    "    def predict(self, X):\n",
    "        sentiment = X[\"sentiment\"]\n",
    "        zscore = self.zscore(X[\"sentiment\"], halflife=self.get_params()[\"window\"])\n",
    "        signal = pd.Series(index=X.index)\n",
    "        signal[sentiment.le(0) & zscore.le(0)] = -1\n",
    "        signal[sentiment.ge(0) | zscore.ge(0)] = 1\n",
    "        signal = signal.ffill().fillna(0)\n",
    "        return self.get_params()[\"direction\"] * signal\n",
    "\n",
    "score_func = partial(sharpe_score, delay=0)\n",
    "score_func_1 = partial(sharpe_score, delay=1)\n",
    "stats = []\n",
    "splitter = WalkForwardSplit(train_size=0.5, test_size=252, gap=0, expanding=True)\n",
    "\n",
    "for index in tqdm(underlyings):\n",
    "    y = utils.get_spot(index)[\"spot\"].diff().shift(-1)[\"2013-01-01\":]\n",
    "    for term, search in spaces.items():\n",
    "        space = {\"window\": search, \"direction\": [-1, 1]}\n",
    "        optimizer = Optimizer(space, score_func)\n",
    "        hybrid = HybridEstimator(SentimentSignal(), optimizer)\n",
    "        models, y_pred = walkforward_training(X, y, hybrid, splitter)\n",
    "        f = y_pred.notnull() & y.notnull()\n",
    "        cnt = f.sum()\n",
    "        score = score_func(y, y_pred)\n",
    "        score_delay = score_func_1(y, y_pred)\n",
    "        direction = np.mean([x[0].base_estimator.get_params()[\"direction\"] for x in models])\n",
    "        best_window = np.mean([x[0].base_estimator.get_params()[\"window\"] for x in models])\n",
    "        zstat =stests.ztest(y[f] * y_pred[f], x2=None, alternative=\"larger\")\n",
    "        d = dict(index=index, name=name, term=term, sharpe=score, sharpe_delay1=score_delay,\n",
    "                 cnt=cnt, zstat=zstat[0], pval=zstat[1], direction=direction, window=best_window)\n",
    "        stats.append(d)\n",
    "stats = pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T10:22:05.171975Z",
     "start_time": "2021-01-05T10:22:05.051086Z"
    }
   },
   "outputs": [],
   "source": [
    "stats = pd.read_csv(\"sentiment_signal_study.csv\")\n",
    "print(\"percentage of trail that passed 5% test:\", 100 * stats[\"pval\"].le(0.05).mean(0))\n",
    "stats.set_index(\"index\").to_csv(\"sentiment_signal_study.csv\")\n",
    "stats[stats[\"pval\"].le(0.05)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDF zscore diff\n",
    "signal that we previously use in AUDJPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:36:23.037951Z",
     "start_time": "2021-01-05T09:36:22.941517Z"
    }
   },
   "outputs": [],
   "source": [
    "class ZScoreDiff(HybridBaseEstimator):\n",
    "    def predict(self, X):\n",
    "        zscore = self.zscore(X[\"sentiment\"], halflife=self.get_params()[\"window\"])\n",
    "        signal = zscore.diff(self.get_params()[\"diff\"])\n",
    "        return self.get_params()[\"direction\"] * np.sign(signal).ffill().fillna(0)\n",
    "\n",
    "spaces = {\n",
    "    \"short\": {\"window\": range(3, 10), \"diff\": range(3, 40, 2)},\n",
    "    \"medium\": {\"window\": range(10, 30), \"diff\": range(15, 120, 5)},\n",
    "}\n",
    "\n",
    "\n",
    "score_func = partial(sharpe_score, delay=0)\n",
    "score_func_1 = partial(sharpe_score, delay=1)\n",
    "\n",
    "splitter = WalkForwardSplit(train_size=0.5, test_size=252, gap=0, expanding=True)\n",
    "\n",
    "X = utils.get_ssl_sentiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### on total return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:43:45.994470Z",
     "start_time": "2021-01-05T09:37:02.797739Z"
    }
   },
   "outputs": [],
   "source": [
    "stats = []\n",
    "tris = [\n",
    "    \"SGDINR\",\n",
    "    \"TRY\",\n",
    "    \"CNHTWD\",\n",
    "    \"TWD1m\",\n",
    "    \"CNH1m\",\n",
    "    \"ADXY\",\n",
    "    \"CNYCNH\",\n",
    "    \"CNH2y\",\n",
    "    \"CNH3m\",\n",
    "    \"HUFCZK\",\n",
    "    \"RUBvsEUR\",\n",
    "    \"CNH3m12m\",\n",
    "    \"IDR1m3m\",\n",
    "    \"CNH12m\",\n",
    "    \"CNH6m\",\n",
    "    \"CNH\",\n",
    "    \"TWD1m3m\",\n",
    "    \"AUDJPY\",\n",
    "    \"TWD3m12m\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for index in tqdm(tris):\n",
    "    y = utils.get_total_return_index(index)[\"tri\"].diff().shift(-1)[\"2013-01-01\":]\n",
    "    # define horizon\n",
    "    for term, search in spaces.items():\n",
    "        space = search.copy()\n",
    "        space.update({\"direction\": [-1, 1]})\n",
    "        optimizer = Optimizer(space, score_func)\n",
    "        hybrid = HybridEstimator(ZScoreDiff(), optimizer)\n",
    "        models, y_pred = walkforward_training(X, y, hybrid, splitter)\n",
    "        f = y_pred.notnull() & y.notnull()\n",
    "        cnt = f.sum()\n",
    "        score = score_func(y, y_pred)\n",
    "        score_delay = score_func_1(y, y_pred)\n",
    "        direction = np.mean([x[0].base_estimator.get_params()[\"direction\"] for x in models])\n",
    "        best_window = np.mean([x[0].base_estimator.get_params()[\"window\"] for x in models])\n",
    "        best_diff = np.mean([x[0].base_estimator.get_params()[\"diff\"] for x in models])\n",
    "        sharpe = score_func(y, y_pred)\n",
    "        \n",
    "        zstat =stests.ztest(y[f] * y_pred[f], x2=None, alternative=\"larger\")\n",
    "        d = dict(index=index, name=\"zscore-diff\", term=term, sharpe=score, sharpe_delay1=score_delay,\n",
    "                 cnt=cnt, zstat=zstat[0], pval=zstat[1], direction=direction, window=best_window, diff=best_diff)\n",
    "        stats.append(d)\n",
    "stats = pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:43:46.144168Z",
     "start_time": "2021-01-05T09:43:45.996305Z"
    }
   },
   "outputs": [],
   "source": [
    "# stats = pd.read_csv(\"sentiment_tri_zscore_diff_study.csv\")\n",
    "print(\"percentage of trail that passed 5% test:\", 100 * stats[\"pval\"].le(0.05).mean(0))\n",
    "stats.set_index(\"index\").to_csv(\"sentiment_tri_zscore_diff_study.csv\")\n",
    "stats[stats[\"pval\"].le(0.05)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### on various assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-05T09:34:00.169993Z",
     "start_time": "2021-01-05T09:33:20.560095Z"
    }
   },
   "outputs": [],
   "source": [
    "underlyings = [\n",
    "    \"SPX\", \"NDX\", \"NKY\", \"HSCEI\", \"HSI\", \"KOSPI2\", \"SX5E\", \"DAX\",\n",
    "    \"HYG\", \"TLT\", \"LQD\",\n",
    "    \"GLD\", \"USO\",\n",
    "    \"USDNOK\", \"USDRUB\", \"USDMXN\", \"AUDJPY\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stats = []\n",
    "splitter = WalkForwardSplit(train_size=0.5, test_size=252, gap=0, expanding=True)\n",
    "\n",
    "for index in tqdm(underlyings):\n",
    "    y = utils.get_spot(index)[\"spot\"].diff().shift(-1)[\"2013-01-01\":]\n",
    "    for term, search in spaces.items():\n",
    "        space = search.copy()\n",
    "        space.update({\"direction\": [-1, 1]})\n",
    "        optimizer = Optimizer(space, score_func)\n",
    "        hybrid = HybridEstimator(ZScoreDiff(), optimizer)\n",
    "        models, y_pred = walkforward_training(X, y, hybrid, splitter)\n",
    "        f = y_pred.notnull() & y.notnull()\n",
    "        cnt = f.sum()\n",
    "        score = score_func(y, y_pred)\n",
    "        score_delay = score_func_1(y, y_pred)\n",
    "        direction = np.mean([x[0].base_estimator.get_params()[\"direction\"] for x in models])\n",
    "        best_window = np.mean([x[0].base_estimator.get_params()[\"window\"] for x in models])\n",
    "        best_diff = np.mean([x[0].base_estimator.get_params()[\"diff\"] for x in models])\n",
    "        sharpe = score_func(y, y_pred)\n",
    "        \n",
    "        zstat =stests.ztest(y[f] * y_pred[f], x2=None, alternative=\"larger\")\n",
    "        d = dict(index=index, name=\"zscore-diff\", term=term, sharpe=score, sharpe_delay1=score_delay,\n",
    "                 cnt=cnt, zstat=zstat[0], pval=zstat[1], direction=direction, window=best_window, diff=best_diff)\n",
    "        stats.append(d)\n",
    "stats = pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T08:41:43.013949Z",
     "start_time": "2021-01-04T08:41:42.976988Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"percentage of trail that passed 5% test:\", 100 * stats[\"pval\"].le(0.05).mean(0))\n",
    "stats.set_index(\"index\").to_csv(\"sentiment_zscore_diff_study.csv\")\n",
    "stats[stats[\"pval\"].le(0.05)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross-asset feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T08:27:06.341795Z",
     "start_time": "2021-01-04T08:27:06.227810Z"
    }
   },
   "outputs": [],
   "source": [
    "vix = utils.get_chained_future('VIX')\n",
    "vix[\"diff\"].cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T08:27:55.660733Z",
     "start_time": "2021-01-04T08:27:55.533922Z"
    }
   },
   "outputs": [],
   "source": [
    "brent = utils.get_chained_future(\"BRENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T08:28:04.866803Z",
     "start_time": "2021-01-04T08:28:04.687211Z"
    }
   },
   "outputs": [],
   "source": [
    "brent[\"diff\"].cumsum().plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
